{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://www.noon.com/egypt-en/electronics-and-mobiles/mobiles-and-accessories/mobiles-20905/eg-all-mobiles/?fisCarousel=true&fis_fbn=1&limit=50&page={}&sortby=popularity&sortdir=desc\"\n",
        "\n",
        "# Initialize lists to store scraped data\n",
        "product_links = []\n",
        "\n",
        "# Pagination loop\n",
        "page = 1\n",
        "while True:\n",
        "    # Request the page\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all product containers\n",
        "    products = soup.find_all('div', class_='sc-19767e73-0 bwele')\n",
        "\n",
        "    if not products:\n",
        "        break  # Stop if no products found on the page\n",
        "\n",
        "    for product in products:\n",
        "\n",
        "        # Extract product link\n",
        "        link = product.find('a', href=True)['href']\n",
        "        full_link = f\"https://www.noon.com{link}\"  # Make sure the URL is complete\n",
        "        product_links.append(full_link)\n",
        "\n",
        "    # Increment page count\n",
        "    page += 1\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "\n",
        "    'Product Link': product_links\n",
        "})\n",
        "\n",
        "# Export to CSV\n",
        "df.to_csv('noon_mobile_links.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpbMe9ojchSO",
        "outputId": "38e894c5-bd46-4e7c-e3a0-6a1b5c614864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping completed and data saved to 'noon_mobile_links.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file with URLs\n",
        "file_path = '/content/noon_mobile_links.csv'\n",
        "urls_df = pd.read_csv(file_path)\n",
        "\n",
        "# Prepare an empty list to collect data\n",
        "all_data = []\n",
        "\n",
        "# Iterate over each URL in the DataFrame\n",
        "for url in urls_df['Product Link']:\n",
        "    # Send a GET request to the webpage\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract the title\n",
        "    title = soup.find('h1', class_='sc-de5a1c50-17 dJnofv').text.strip()\n",
        "\n",
        "    # Extract the price\n",
        "    price = soup.find('div', class_='priceNow').text.strip() if soup.find('div', class_='priceNow') else 'N/A'\n",
        "\n",
        "    # Extract the availability\n",
        "    availability = 'Available' if soup.find('button', class_='sc-qGWeR') else 'Out of stock'\n",
        "\n",
        "    # Extract the specifications table\n",
        "    specifications = {}\n",
        "    specs_table = soup.find('table').find('tbody').find_all('tr')\n",
        "\n",
        "    for row in specs_table:\n",
        "        # Get the header (first column) and value (second column)\n",
        "        header = row.find_all('td')[0].text.strip()\n",
        "        value = row.find_all('td')[1].text.strip()\n",
        "        specifications[header] = value\n",
        "\n",
        "    # Add title, price, and availability to specifications\n",
        "    specifications['Title'] = title\n",
        "    specifications['Price'] = price\n",
        "    specifications['Availability'] = availability\n",
        "\n",
        "    # Append the specifications as a row to the list\n",
        "    all_data.append(specifications)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "specs_df = pd.DataFrame(all_data)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "specs_df.to_csv('/content/noon_mobile_Data.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QGK4yAZAka_O",
        "outputId": "0eda6d88-9d51-47d9-c278-5ac7da85f517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/noon_mobile_Data.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}